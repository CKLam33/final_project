{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/I/Degree/lv6/final_project/.venv/lib/python3.11/site-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /mnt/I/Degree/lv6/final_project/test_result/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from RMZ3Env import make_RMZ3Env\n",
    "from gymnasium.wrappers import NormalizeObservation\n",
    "from env_setup import *\n",
    "\n",
    "PATH = Path(\"test_result\")\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "env_config = {\n",
    "        \"gba_rom\": GBA_ROM,\n",
    "        \"gba_sav\": GBA_SAV,\n",
    "        \"max_run_time\": MAX_TIME,\n",
    "        \"include_lives_count\": INCLUDE_LIVES,\n",
    "        \"render_mode\": \"rgb_array\",\n",
    "        \"frameskip\": FRAMESKIP,\n",
    "        \"mgba_silence\": SILENCE,\n",
    "        \"to_resize\": RESIZE,\n",
    "        \"scrn_w\": SCRN_W,\n",
    "        \"scrn_h\": SCRN_H,\n",
    "        \"to_grayscale\": GARYSCALE,\n",
    "        \"record\": True,\n",
    "        \"record_path\": PATH.joinpath(\"videos/\")}\n",
    "\n",
    "env = make_RMZ3Env(**env_config)\n",
    "env = NormalizeObservation(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma, pickle\n",
    "from CNNLSTM import CNNLSTM\n",
    "from evotorch.neuroevolution.net.vecrl import Policy\n",
    "\n",
    "model = CNNLSTM(env.observation_space.shape, env.action_space.n, HIDDEN_SIZE, NUM_LAYERS)\n",
    "\n",
    "with lzma.open(\"EA/PGPE_CNNLSTM/searcher_status_2025-03-27 16_06_02.186381.xz\", \"rb\") as f:\n",
    "    status = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution from PGPE model:  center\n",
      "Solution from PGPE model:  pop_best\n",
      "Solution from PGPE model:  best\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "test_solutions = [\"center\", \"pop_best\", \"best\"]\n",
    "policy = Policy(model)\n",
    "results = {}\n",
    "for solution in test_solutions:\n",
    "    print(\"Solution from PGPE model: \", solution)\n",
    "    if \"PGPE_\" + solution not in results:\n",
    "        results[\"PGPE_\" + solution] = pd.DataFrame(columns=[\"Rewards\", \"Best stages - checkpoint\", \"Total play time\"])\n",
    "    policy.set_parameters(status[solution])\n",
    "    for i in range(20):\n",
    "        env.set_wrapper_attr(\"name_prefix\", f\"PGPE_{solution}_{i}\")\n",
    "        obs, info = env.reset()\n",
    "        while True:\n",
    "            action = np.argmax(policy(torch.as_tensor(obs, dtype=torch.float32, device=\"cpu\")))\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            env.render()\n",
    "            if terminated or truncated:\n",
    "                rewards = info[\"total_rewards\"]\n",
    "                curr_stage = info[\"current_stage\"]\n",
    "                curr_checkpoint = info[\"current_checkpoint\"]\n",
    "                total_play_time = info[\"total_play_time\"]\n",
    "                results[\"PGPE_\" + solution].loc[len(results[\"PGPE_\" + solution])] = [rewards, (curr_stage, curr_checkpoint), total_play_time]\n",
    "                env.close()\n",
    "                policy.reset()\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/I/Degree/lv6/final_project/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to use hipBLASLt on an unsupported architecture! Overriding blas backend to hipblas (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:343.)\n",
      "  return F.linear(input, self.weight, self.bias)\n"
     ]
    }
   ],
   "source": [
    "from sb3_contrib import RecurrentPPO\n",
    "rppo = RecurrentPPO.load(\"RL/RecurrentPPO/RPPO_model_2025-03-26 13_11_00.498926\")\n",
    "results[\"RPPO\"] = pd.DataFrame(columns=[\"Rewards\", \"Best stages - checkpoint\", \"Total play time\"])\n",
    "for i in range(20):\n",
    "    env.set_wrapper_attr(\"name_prefix\", f\"RPPO_{solution}_{i}\")\n",
    "    obs, info = env.reset()\n",
    "    lstm_states = None\n",
    "    # Episode start signals are used to reset the lstm states\n",
    "    episode_start = None\n",
    "    while True:\n",
    "        action, lstm_states = rppo.predict(obs, state=lstm_states, episode_start=episode_start, deterministic = True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        episode_starts = truncated | terminated\n",
    "        env.render()\n",
    "        if terminated or truncated:\n",
    "            rewards = info[\"total_rewards\"]\n",
    "            curr_stage = info[\"current_stage\"]\n",
    "            curr_checkpoint = info[\"current_checkpoint\"]\n",
    "            total_play_time = info[\"total_play_time\"]\n",
    "            results[\"RPPO\"].loc[len(results[\"RPPO\"])] = [rewards, (curr_stage, curr_checkpoint), total_play_time]\n",
    "            env.close()\n",
    "            policy.reset()\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PGPE_center':        Rewards Best stages - checkpoint  Total play time\n",
       " 0   661.040165                   (1, 3)        50.000000\n",
       " 1   660.058805                   (1, 3)        50.066667\n",
       " 2   665.002116                   (1, 3)        50.050000\n",
       " 3   663.037248                   (1, 3)        50.066667\n",
       " 4   662.022812                   (1, 3)        50.000000\n",
       " 5   658.035317                   (1, 3)        50.050000\n",
       " 6   657.106763                   (1, 3)        50.000000\n",
       " 7   660.038262                   (1, 3)        50.050000\n",
       " 8   661.042533                   (1, 3)        50.016667\n",
       " 9   659.029757                   (1, 3)        50.050000\n",
       " 10  660.000868                   (1, 3)        50.016667\n",
       " 11  660.022491                   (1, 3)        50.066667\n",
       " 12  665.971625                   (1, 3)        50.033333\n",
       " 13  656.064090                   (1, 3)        50.066667\n",
       " 14  657.065935                   (1, 3)        50.033333\n",
       " 15  661.046248                   (1, 3)        50.033333\n",
       " 16  658.068402                   (1, 3)        50.016667\n",
       " 17  663.004144                   (1, 3)        50.033333\n",
       " 18  662.022199                   (1, 3)        50.066667\n",
       " 19  657.067769                   (1, 3)        50.000000,\n",
       " 'PGPE_pop_best':        Rewards Best stages - checkpoint  Total play time\n",
       " 0   661.029902                   (1, 3)        50.000000\n",
       " 1   659.078873                   (1, 3)        50.016667\n",
       " 2   663.962659                   (1, 3)        50.033333\n",
       " 3   655.093172                   (1, 3)        50.016667\n",
       " 4   655.099104                   (1, 3)        50.016667\n",
       " 5   658.065812                   (1, 3)        50.066667\n",
       " 6   658.086145                   (1, 3)        50.016667\n",
       " 7   658.088123                   (1, 3)        50.033333\n",
       " 8   655.082187                   (1, 3)        50.050000\n",
       " 9   663.010220                   (1, 3)        50.033333\n",
       " 10  659.044998                   (1, 3)        50.016667\n",
       " 11  655.106352                   (1, 3)        50.000000\n",
       " 12  662.001706                   (1, 3)        50.066667\n",
       " 13  661.004507                   (1, 3)        50.050000\n",
       " 14  656.084588                   (1, 3)        50.016667\n",
       " 15  659.050963                   (1, 3)        50.016667\n",
       " 16  654.125665                   (1, 3)        50.000000\n",
       " 17  659.052401                   (1, 3)        50.000000\n",
       " 18  662.031375                   (1, 3)        50.000000\n",
       " 19  660.064257                   (1, 3)        50.016667,\n",
       " 'PGPE_best':        Rewards Best stages - checkpoint  Total play time\n",
       " 0   658.064445                   (1, 3)        50.016667\n",
       " 1   657.073318                   (1, 3)        50.000000\n",
       " 2   663.020572                   (1, 3)        50.050000\n",
       " 3   662.013698                   (1, 3)        50.000000\n",
       " 4   658.061531                   (1, 3)        50.016667\n",
       " 5   659.026235                   (1, 3)        50.033333\n",
       " 6   662.942606                   (1, 3)        50.033333\n",
       " 7   659.059700                   (1, 3)        50.050000\n",
       " 8   661.945117                   (1, 3)        50.000000\n",
       " 9   663.944702                   (1, 3)        50.050000\n",
       " 10  658.052177                   (1, 3)        50.016667\n",
       " 11  663.025857                   (1, 3)        50.033333\n",
       " 12  664.013916                   (1, 3)        50.016667\n",
       " 13  663.005954                   (1, 3)        50.000000\n",
       " 14  660.019567                   (1, 3)        50.016667\n",
       " 15  661.018241                   (1, 3)        50.016667\n",
       " 16  661.968012                   (1, 3)        50.033333\n",
       " 17  663.998448                   (1, 3)        50.050000\n",
       " 18  658.048963                   (1, 3)        50.050000\n",
       " 19  663.993566                   (1, 3)        50.066667,\n",
       " 'RPPO':        Rewards Best stages - checkpoint  Total play time\n",
       " 0   488.390446                   (1, 3)        50.016667\n",
       " 1   557.990969                   (1, 3)        50.033333\n",
       " 2   660.020631                   (1, 3)        50.033333\n",
       " 3   661.031411                   (1, 3)        50.033333\n",
       " 4   659.027928                   (1, 3)        50.000000\n",
       " 5   660.051055                   (1, 3)        50.033333\n",
       " 6   664.980040                   (1, 3)        50.033333\n",
       " 7   600.558310                   (1, 3)        50.033333\n",
       " 8   661.064467                   (1, 3)        50.016667\n",
       " 9   659.032798                   (1, 3)        50.000000\n",
       " 10  656.080574                   (1, 3)        50.050000\n",
       " 11  662.023942                   (1, 3)        50.050000\n",
       " 12  659.051921                   (1, 3)        50.000000\n",
       " 13  662.001455                   (1, 3)        50.016667\n",
       " 14  655.099373                   (1, 3)        50.050000\n",
       " 15  663.011697                   (1, 3)        50.050000\n",
       " 16  665.993975                   (1, 3)        50.066667\n",
       " 17  661.052603                   (1, 3)        50.016667\n",
       " 18  665.000576                   (1, 3)        50.033333\n",
       " 19  656.061858                   (1, 3)        50.016667}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGPE_center :\n",
      "Mean reward:  660.337377406842\n",
      "Best stage-checkpoint:  (1, 3)\n",
      "Mean play time:  50.035833333333876\n",
      "PGPE_pop_best :\n",
      "Mean reward:  658.7081504273775\n",
      "Best stage-checkpoint:  (1, 3)\n",
      "Mean play time:  50.02333333333387\n",
      "PGPE_best :\n",
      "Mean reward:  661.1148312422805\n",
      "Best stage-checkpoint:  (1, 3)\n",
      "Mean play time:  50.02750000000054\n",
      "RPPO :\n",
      "Mean reward:  643.876301545062\n",
      "Best stage-checkpoint:  (1, 3)\n",
      "Mean play time:  50.02916666666721\n"
     ]
    }
   ],
   "source": [
    "for sol, v in results.items():\n",
    "    print(sol, \":\")\n",
    "    print(\"Mean reward: \", v[\"Rewards\"].mean())\n",
    "    print(\"Best stage-checkpoint: \", v[\"Best stages - checkpoint\"].max())\n",
    "    print(\"Mean play time: \", v[\"Total play time\"].mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
